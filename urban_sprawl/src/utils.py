import ee
import geemap
import geopandas as gpd
import pandas as pd
import rasterio
import os
import matplotlib.pyplot as plt
import calendar
from shapely.geometry import Polygon, MultiPolygon
from rasterio.features import shapes
from datetime import date

def authenticate_gee(project='bosques-bogota-416214'):
    try:
        ee.Initialize(project=project)
    except Exception:
        print("üîê Autenticando por primera vez...")
        ee.Authenticate()
        ee.Initialize(project=project)

def load_geometry(path):
    """
    Carga una o varias geometr√≠as desde un shapefile o GeoJSON y
    devuelve una geometr√≠a Earth Engine combinada (uni√≥n de todas).
    """
    gdf = gpd.read_file(path)

    # Verificar cu√°ntas geometr√≠as hay
    if len(gdf) == 0:
        raise ValueError("El archivo de geometr√≠a est√° vac√≠o.")
    
    # Unir todas las geometr√≠as en una sola
    geom_union = gdf.unary_union

    # Convertir a geometr√≠a de EE
    if isinstance(geom_union, Polygon):
        coords = list(geom_union.exterior.coords)
        geometry = ee.Geometry.Polygon(coords)
    elif isinstance(geom_union, MultiPolygon):
        polygons = [ee.Geometry.Polygon(list(poly.exterior.coords)) for poly in geom_union.geoms]
        geometry = ee.Geometry.MultiPolygon(polygons)
    else:
        raise ValueError("La geometr√≠a no es Polygon ni MultiPolygon.")

    return geometry

def get_monthly_periods(month: int, year: int):
    """
    Genera autom√°ticamente las fechas de comparaci√≥n mensual
    (mes anterior vs mes actual) en formato ISO (YYYY-MM-DD).

    Ejemplo:
    >>> get_monthly_periods(10, 2025)
    (('2025-09-01', '2025-09-30'), ('2025-10-01', '2025-10-31'))
    """
    if month == 1:
        prev_month = 12
        prev_year = year - 1
    else:
        prev_month = month - 1
        prev_year = year

    # Primer y √∫ltimo d√≠a de cada mes
    first_day_prev = date(prev_year, prev_month, 1)
    last_day_prev = date(prev_year, prev_month, calendar.monthrange(prev_year, prev_month)[1])
    first_day_curr = date(year, month, 1)
    last_day_curr = date(year, month, calendar.monthrange(year, month)[1])

    periodo_antes = (first_day_prev.isoformat(), last_day_prev.isoformat())
    periodo_despues = (first_day_curr.isoformat(), last_day_curr.isoformat())

    return periodo_antes, periodo_despues

def get_dw_median(year, geometry):
    start = ee.Date(f"{year}-01-01")
    end = start.advance(1, 'year')
    dw = ee.ImageCollection('GOOGLE/DYNAMICWORLD/V1') \
        .filterDate(start, end) \
        .filterBounds(geometry) \
        .select('built')
    return dw.median().clip(geometry)

def get_dw_median_period(start_date, end_date, geometry):
    """
    Calcula la mediana de probabilidad de la clase 'built' (Dynamic World)
    para un periodo de fechas espec√≠fico. Si el periodo no tiene im√°genes,
    devuelve una imagen vac√≠a con valores 0 para evitar errores posteriores.
    """
    start = ee.Date(start_date)
    end = ee.Date(end_date)

    dw = (
        ee.ImageCollection("GOOGLE/DYNAMICWORLD/V1")
        .filterDate(start, end)
        .filterBounds(geometry)
        .select("built")
    )

    count = dw.size()
    # Si hay im√°genes, calcula la mediana; si no, crea una imagen con valores 0
    dw_median = ee.Image(
        ee.Algorithms.If(count.gt(0), dw.median(), ee.Image(0).rename("built"))
    )

    # Mensaje informativo
    print(f"üìÖ Dynamic World {start_date} ‚Üí {end_date}: {count.getInfo()} im√°genes disponibles")

    return dw_median.clip(geometry)


def export_image(image, geometry, output_path):
    print(f"üíæ Descargando imagen a: {output_path}")
    geemap.download_ee_image(
        image=image,
        filename=output_path,
        region=geometry.bounds(),
        scale=10,
        crs='EPSG:4326'
    )
    print("‚úÖ Descarga completada.")

def download_sentinel_rgb(geometry, start_date, end_date, output_path, scale=10):
    """
    Descarga una imagen Sentinel-2 RGB (B4, B3, B2) como mediana del periodo especificado.
    Si no hay im√°genes disponibles, no intenta descargar y muestra advertencia.
    """
    import geemap
    import ee

    start = ee.Date(start_date)
    end = ee.Date(end_date)

    print(f"‚¨áÔ∏è Descargando Sentinel-2 RGB entre {start_date} y {end_date}...")

    collection = (
        ee.ImageCollection("COPERNICUS/S2_SR_HARMONIZED")
        .filterBounds(geometry)
        .filterDate(start, end)
        .filter(ee.Filter.lt("CLOUDY_PIXEL_PERCENTAGE", 30))
        .select(["B4", "B3", "B2"])
    )

    count = collection.size().getInfo()
    print(f"üì¶ {count} im√°genes disponibles en el rango.")

    if count == 0:
        print("‚ö†Ô∏è No hay im√°genes Sentinel-2 disponibles en este rango. Se omite descarga.")
        return None

    image = collection.median().clip(geometry)

    try:
        geemap.download_ee_image(
            image=image,
            filename=output_path,
            region=geometry.bounds(),
            scale=scale,
            crs="EPSG:4326"
        )
        print(f"‚úÖ Imagen Sentinel-2 descargada: {output_path}")
        return output_path
    except Exception as e:
        print(f"‚ö†Ô∏è Error al descargar Sentinel-2: {e}")
        return None


def create_intersections(new_urban_tif, sac_path, reserva_path, eep_path, output_dir):
    """
    Convierte el raster de expansi√≥n urbana a pol√≠gonos y calcula intersecciones
    con SAC, Reservas y EEP. Tambi√©n guarda los pol√≠gonos sin intersecci√≥n.
    """
    print("üîç Generando pol√≠gonos de expansi√≥n urbana e intersecciones...")
    with rasterio.open(new_urban_tif) as src:
        mask = src.read(1) > 0
        results = (
            {"properties": {"value": v}, "geometry": s}
            for s, v in shapes(src.read(1), mask=mask, transform=src.transform)
        )
        gdf_newurban = gpd.GeoDataFrame.from_features(results, crs=src.crs)

    gdf_sac = gpd.read_file(sac_path).to_crs(gdf_newurban.crs)
    gdf_res = gpd.read_file(reserva_path).to_crs(gdf_newurban.crs)
    gdf_eep = gpd.read_file(eep_path).to_crs(gdf_newurban.crs)

    gdf_inter_sac = gpd.overlay(gdf_newurban, gdf_sac, how="intersection")
    gdf_inter_res = gpd.overlay(gdf_newurban, gdf_res, how="intersection")
    gdf_inter_eep = gpd.overlay(gdf_newurban, gdf_eep, how="intersection")

    gdf_inter_sac.to_file(os.path.join(output_dir, "intersec_sac.geojson"))
    gdf_inter_res.to_file(os.path.join(output_dir, "intersec_reserva.geojson"))
    gdf_inter_eep.to_file(os.path.join(output_dir, "intersec_eep.geojson"))

    intersected = gpd.GeoDataFrame(pd.concat([gdf_inter_sac, gdf_inter_res, gdf_inter_eep], ignore_index=True))
    intersected.to_file(os.path.join(output_dir, "new_urban_intersections.geojson"))
    no_inter = gpd.overlay(gdf_newurban, intersected, how="difference")
    no_inter.to_file(os.path.join(output_dir, "new_urban_no_intersections.geojson"))

    print("‚úÖ Intersecciones creadas correctamente.")

def calculate_expansion_areas(
    output_dir,
    input_dir,
    upl_path,
    bogota_buffer_path=None,
    save_summary=True
):
    """
    Calcula √°reas de expansi√≥n urbana (en m¬≤) por UPL,
    diferenciando intersecci√≥n y no intersecci√≥n.
    Si se proporciona bogota_buffer_path, tambi√©n calcula el √°rea
    de expansi√≥n dentro del buffer urbano.
    """

    print("üìè Calculando √°reas de expansi√≥n urbana (m¬≤)...")
    crs = "EPSG:9377"
    
    # === Leer intersecciones y no intersecciones ===
    gdf_no  = gpd.read_file(os.path.join(input_dir, "new_urban_no_intersections.geojson")).to_crs(crs)
    gdf_no["area_m2"] = gdf_no.geometry.area
    
    gdf_inter = gpd.read_file(os.path.join(input_dir, "new_urban_intersections.geojson")).to_crs(crs)
    gdf_inter["area_m2"] = gdf_inter.geometry.area

    # === Leer UPL ===
    gdf_upl = gpd.read_file(upl_path).to_crs(crs)

    # === Calcular √°reas por UPL ===
    inter_upl = gpd.overlay(gdf_upl, gdf_inter, how="intersection")
    nointer_upl = gpd.overlay(gdf_upl, gdf_no, how="intersection")

    inter_upl["area_ha"] = inter_upl.geometry.area/10000
    nointer_upl["area_ha"] = nointer_upl.geometry.area/10000

    resumen_upl = (
        inter_upl.groupby("NOMBRE")["area_ha"].sum().reset_index().rename(columns={"area_ha": "interseccion_ha"})
        .merge(
            nointer_upl.groupby("NOMBRE")["area_ha"].sum().reset_index().rename(columns={"area_ha": "no_interseccion_ha"}),
            on="NOMBRE",
            how="outer"
        )
        .fillna(0)
    )
    resumen_upl["total_ha"] = resumen_upl["interseccion_ha"] + resumen_upl["no_interseccion_ha"]

    # === Calcular √°rea dentro del buffer urbano (si se proporciona) ===
    if bogota_buffer_path and os.path.exists(bogota_buffer_path):
        print("üèôÔ∏è Calculando √°rea de expansi√≥n dentro del buffer urbano...")
        gdf_buffer = gpd.read_file(bogota_buffer_path).to_crs(crs)

        # 1Ô∏è‚É£ Intersecci√≥n entre buffer y √°reas con intersecci√≥n (SAC, Reserva, EEP)
        inter_buffer_inter = gpd.overlay(gdf_buffer, gdf_inter, how="intersection")
        inter_buffer_inter["area_ha"] = inter_buffer_inter.geometry.area / 10_000

        # 2Ô∏è‚É£ Intersecci√≥n entre buffer y √°reas SIN intersecci√≥n
        inter_buffer_no = gpd.overlay(gdf_buffer, gdf_no, how="intersection")
        inter_buffer_no["area_ha"] = inter_buffer_no.geometry.area / 10_000

        # 3Ô∏è‚É£ Total (sumando ambas)
        inter_buffer_total = pd.concat([inter_buffer_inter, inter_buffer_no], ignore_index=True)
        inter_buffer_total["area_ha"] = inter_buffer_total.geometry.area / 10_000

        # --- Resumen ---
        resumen_buffer = pd.DataFrame({
            "zona": ["Bogot√° urbana (buffer)"],
            "interseccion_ha": [round(inter_buffer_inter["area_ha"].sum(), 2)],
            "no_interseccion_ha": [round(inter_buffer_no["area_ha"].sum(), 2)],
            "total_ha": [round(inter_buffer_total["area_ha"].sum(), 2)]
        })

        resumen_buffer.to_csv(os.path.join(output_dir, "resumen_buffer_ha.csv"), index=False, encoding="utf-8")
        print(f"‚úÖ Resumen del buffer urbano guardado en: resumen_buffer_ha.csv")

    else:
        print("‚ö†Ô∏è No se proporcion√≥ bogota_buffer_path o el archivo no existe. Saltando c√°lculo del buffer.")


    # === Guardar resultados principales ===
    if save_summary:
        resumen_upl.to_csv(os.path.join(output_dir, "resumen_expansion_upl_ha.csv"), index=False, encoding="utf-8")
        print("‚úÖ Archivo guardado: resumen_expansion_upl_ha.csv")

    return resumen_upl, resumen_buffer

def build_urban_report_json(resumen_upl, resumen_buffer, mapa_interactivo_path, maps_dir, year1, year2, output_json):
    """
    Construye el JSON para el reporte final de expansi√≥n urbana.
    """
    print("üìù Construyendo JSON del reporte urbano...")

    # Top 5 UPLs con mayor expansi√≥n
    resumen_upl = resumen_upl.copy()
    resumen_upl["total_ha"] = resumen_upl["total_m2"] / 10000
    resumen_upl["interseccion_ha"] = resumen_upl["interseccion_m2"] / 10000
    resumen_upl["no_interseccion_ha"] = resumen_upl["no_interseccion_m2"] / 10000
    upls_top5 = resumen_upl.sort_values("total_ha", ascending=False).head(5).to_dict(orient="records")

    # Centroides de expansi√≥n (clusters)
    inter_path = os.path.join(maps_dir.replace("maps", "intersections"), "new_urban_intersections.geojson")
    if os.path.exists(inter_path):
        gdf_inter = gpd.read_file(inter_path).to_crs("EPSG:4326")
        centroids = [{"id": i+1, "lat": round(pt.y, 5), "lon": round(pt.x, 5)} for i, pt in enumerate(gdf_inter.centroid)]
    else:
        centroids = []

    data = {
        "YEAR1": year1,
        "YEAR2": year2,
        "UPLS_TOP5": upls_top5,
        "MAPA_INTERACTIVO": mapa_interactivo_path,
        "CENTROIDES": centroids
    }

    with open(output_json, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    print(f"‚úÖ JSON guardado: {output_json}")
    return data

def convert_tif_to_png(tif_path, out_png):
    """Convierte un .tif RGB a .png visible para Folium."""
    import numpy as np
    import rasterio

    with rasterio.open(tif_path) as src:
        img = src.read([1, 2, 3])  # RGB
        img = np.transpose(img, (1, 2, 0))
        img = (img - img.min()) / (img.max() - img.min())  # normalizar
        plt.imsave(out_png, img)
    return out_png

from shapely.ops import unary_union

def create_growth_clusters(gdf_path, buffer_distance=500, crs="EPSG:9377"):
    """
    Crea clusters de crecimiento urbano agrupando pol√≠gonos que se tocan
    o est√°n a una distancia menor al buffer indicado.
    """
    print("üß© Creando clusters de expansi√≥n urbana...")

    gdf = gpd.read_file(gdf_path).to_crs(crs)
    gdf["geometry_buffer"] = gdf.geometry.buffer(buffer_distance)
    gdf = gdf.reset_index(drop=True)

    # Lista para asignar IDs
    gdf["cluster_id"] = -1
    cluster_id = 0

    for i in range(len(gdf)):
        if gdf.loc[i, "cluster_id"] != -1:
            continue  # ya asignado

        cluster_id += 1
        current = gdf.loc[[i], "geometry_buffer"].values[0]
        members = [i]
        changed = True

        # Expandir el cluster con cualquier buffer que toque al actual
        while changed:
            overlaps = gdf[gdf.geometry_buffer.intersects(current) & (gdf.cluster_id == -1)]
            if len(overlaps) > 0:
                idxs = overlaps.index.tolist()
                gdf.loc[idxs, "cluster_id"] = cluster_id
                members.extend(idxs)
                current = unary_union(gdf.loc[members, "geometry_buffer"])
            else:
                changed = False

    # Restaurar geometr√≠a original y calcular √°rea real
    gdf["area_ha"] = gdf.geometry.area / 10000
    gdf.drop(columns=["geometry_buffer"], inplace=True)

    print(f"‚úÖ {cluster_id} clusters creados correctamente.")
    return gdf

